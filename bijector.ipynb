{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "tfd = tf.contrib.distributions\n",
    "tfb = tfd.bijectors\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTYPE=tf.float32\n",
    "NP_DTYPE=np.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.17694308, 0.12909111, 0.22869545, 0.22170349,\n",
       "        0.24356687],\n",
       "       [0.        , 0.23328833, 0.25628785, 0.13661589, 0.1210035 ,\n",
       "        0.25280443],\n",
       "       [0.        , 0.18656903, 0.13401585, 0.14672721, 0.22498145,\n",
       "        0.30770645]])"
      ]
     },
     "execution_count": 756,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomly assign unnormalized values to piecewise PDF, here we will be using a total of 6 dimensions (|B|=3)\n",
    "QMat = np.random.rand(3,5)\n",
    "# normalize the piecewise PDF such that the integral is 1\n",
    "QMat = tf.nn.softmax(QMat)\n",
    "# Insert a 0 to the beginning to match the size to the bin array\n",
    "QMat = np.insert(QMat,0,0,axis=1)\n",
    "# Print out values of Q for testing purposes\n",
    "QMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network in the coupling layer\n",
    "def net(x, outsize, nbins):\n",
    "    # Note: Need to put in actual matrix, this is just to test\n",
    "    return QMat\n",
    "    return tf.softmax(layers.stack(x, layers.full_connected, [512, 512, out_size]))\n",
    "\n",
    "class PiecewiseLinear(tfb.Bijector):\n",
    "    \"\"\"\n",
    "    Piecewise Linear: based on 1808.03856\n",
    "    \"\"\"\n",
    "    def __init__(self, D, d, nbins, layer_id=0, validate_args=False, name=\"PiecewiseLinear\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            D: number of dimensions\n",
    "            d: First d units are pass-thru units.\n",
    "        \"\"\"\n",
    "        super(PiecewiseLinear, self).__init__(\n",
    "            forward_min_event_ndims=1, validate_args=validate_args, name=name\n",
    "        )\n",
    "        self.D, self.d = D, d\n",
    "        self.id = layer_id\n",
    "        self.nbins = nbins\n",
    "        self.width = 1.0/self.nbins\n",
    "        \n",
    "    def Q(self, xd):\n",
    "        with tf.variable_scope('Q%d' % self.id, reuse=tf.AUTO_REUSE):\n",
    "            return net(xd, self.D - self.d, self.nbins)\n",
    "        \n",
    "    def pdf(self,x):\n",
    "        xd, xD = x[:, :self.d], x[:, self.d:]\n",
    "        Q = self.Q(xd)\n",
    "        ibins = np.array(np.floor(xD*self.nbins),dtype=np.int32)\n",
    "        return tf.concat([xd, Q[np.arange(len(Q)),ibins]], axis=1)\n",
    "        \n",
    "    def _forward(self, x):\n",
    "        \"Calculate forward coupling layer\"\n",
    "        xd, xD = x[:, :self.d], x[:, self.d:]\n",
    "        Q = self.Q(xd)\n",
    "        ibins = np.array(np.floor(xD*self.nbins),dtype=np.int32)\n",
    "        yD = (xD*self.nbins-ibins)*Q[np.arange(len(Q)),ibins+1]+np.cumsum(Q,axis=1)[np.arange(len(Q)),ibins]\n",
    "        return tf.concat([xd, yD], axis=1)\n",
    "        \n",
    "    def _inverse(self, y):\n",
    "        \"Calculate inverse coupling layer\"\n",
    "        yd, yD = y[:, :self.d], y[:, self.d:]\n",
    "        Q = self.Q(yd)\n",
    "        ibins = tf.transpose(tf.searchsorted(np.cumsum(Q,axis=1),tf.transpose(yD),side='right'))-1\n",
    "        xD = ((yD-np.cumsum(Q,axis=1)[np.arange(len(Q)),ibins])*tf.reciprocal(Q[np.arange(len(Q)),ibins+1])+np.array(ibins,dtype=np.float32))*self.width\n",
    "        return tf.concat([yd, xD], axis=1)\n",
    "    \n",
    "    def _forward_log_det_jacobian(self, x):\n",
    "        \"Calculate log determinant of Coupling Layer\"\n",
    "        xd, xD = x[:, :self.d], x[:, self.d:]\n",
    "        Q = self.Q(xd)\n",
    "        ibins = np.array(np.floor(xD*self.nbins),dtype=np.int32)\n",
    "        return tf.reduce_sum(tf.log(Q[np.arange(len(Q)),ibins]/self.width),axis=-1)\n",
    "    \n",
    "    def _inverse_log_det_jacobian(self, y):\n",
    "        \"Calculate log determinant of Coupling Layer\"\n",
    "        yd, yD = y[:, :self.d], y[:, self.d:]\n",
    "        Q = self.Q(yd)\n",
    "        ibins = tf.transpose(tf.searchsorted(np.cumsum(Q,axis=1),tf.transpose(yD),side='right'))-1\n",
    "        return -tf.reduce_sum(tf.log(Q[np.arange(len(Q)),ibins]/self.width),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = PiecewiseLinear(6,3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=9350, shape=(2, 6), dtype=float64, numpy=\n",
       "array([[0.1       , 0.2       , 0.3       , 0.30603419, 0.55788413,\n",
       "        0.4673121 ],\n",
       "       [0.6       , 0.5       , 0.4       , 0.        , 0.23328833,\n",
       "        0.09328452]])>"
      ]
     },
     "execution_count": 783,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward = test._forward(np.array([[0.1,0.2,0.3,0.4,0.5,0.6],[0.6,0.5,0.4,0.0,0.2,0.1]]).reshape(2,6))\n",
    "forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=9404, shape=(2, 6), dtype=float64, numpy=\n",
       "array([[0.1, 0.2, 0.3, 0.4, 0.5, 0.6],\n",
       "       [0.6, 0.5, 0.4, 0. , 0.2, 0.1]])>"
      ]
     },
     "execution_count": 784,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test._inverse(forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=9451, shape=(1, 6), dtype=float64, numpy=\n",
       "array([[0.17224058, 0.17224058, 0.17224058, 0.19468473, 0.14766326,\n",
       "        0.18464005]])>"
      ]
     },
     "execution_count": 785,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse = test._inverse(np.array([0.17224058,0.17224058,0.17224058,0.17224058,0.17224058,0.17224058]).reshape(1,6))\n",
    "inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=9473, shape=(1, 6), dtype=float64, numpy=\n",
       "array([[0.17224058, 0.17224058, 0.17224058, 0.17224058, 0.17224058,\n",
       "        0.17224058]])>"
      ]
     },
     "execution_count": 786,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test._forward(inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=9478, shape=(1, 6), dtype=float64, numpy=\n",
       "array([[0.1       , 0.2       , 0.3       , 0.12909111, 0.25628785,\n",
       "        0.14672721]])>"
      ]
     },
     "execution_count": 787,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.pdf(np.array([[0.1,0.2,0.3,0.4,0.5,0.6]]).reshape(1,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=9483, shape=(1,), dtype=float64, numpy=array([-0.49955723])>"
      ]
     },
     "execution_count": 788,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test._forward_log_det_jacobian(np.array([[0.1,0.2,0.3,0.4,0.5,0.6]]).reshape(1,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=9519, shape=(1,), dtype=float64, numpy=array([0.49955723])>"
      ]
     },
     "execution_count": 789,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test._inverse_log_det_jacobian(np.array([[0.1,0.2,0.3,0.4,0.5,0.6]]).reshape(1,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.29250357, 0.14247968, 0.17536833, 0.20988416,\n",
       "        0.17976427],\n",
       "       [0.        , 0.23481226, 0.24852722, 0.13220091, 0.19999276,\n",
       "        0.18446685],\n",
       "       [0.        , 0.21736813, 0.27865387, 0.13870695, 0.15994708,\n",
       "        0.20532397]])"
      ]
     },
     "execution_count": 790,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WMat = np.random.rand(3,5)\n",
    "WMat = tf.nn.softmax(WMat)\n",
    "WMat = np.insert(WMat,0,0,axis=1)\n",
    "WMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.32894271 0.50643136 0.69998118 0.86090807 1.        ]\n",
      " [0.         0.25404276 0.52529236 0.64645992 0.83641251 1.        ]\n",
      " [0.         0.30678593 0.54008939 0.66455499 0.8168353  1.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 1.17823131, 1.07092221, 1.42050187, 0.78685014,\n",
       "        0.74663279, 0.80085974],\n",
       "       [0.        , 1.08358087, 1.08021388, 1.10264233, 0.73043977,\n",
       "        1.16915488, 0.60446994],\n",
       "       [0.        , 1.91811224, 0.90461925, 0.76988437, 1.02477128,\n",
       "        0.87936234, 0.90479077]])"
      ]
     },
     "execution_count": 940,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomly assign unnormalized values to piecewise PDF, here we will be using a total of 6 dimensions (|B|=3)\n",
    "VMat = np.random.rand(3,6)\n",
    "expV = tf.exp(VMat)\n",
    "VDenom = np.sum(0.5*(expV[:,0:5]+expV[:,1:6])*WMat[:,1:6],axis=1,keepdims=True)\n",
    "# normalize the piecewise PDF such that the integral is 1\n",
    "VMat = np.true_divide(expV,VDenom)\n",
    "VMat = np.insert(VMat,0,0,axis=1)\n",
    "# Print out values of Q for testing purposes\n",
    "print(np.cumsum((VMat[:,1:7]+VMat[:,0:6])*WMat/2.0,axis=1))\n",
    "VMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network in the coupling layer\n",
    "def netV(x, outsize, nbins):\n",
    "    # Note: Need to put in actual matrix, this is just to test\n",
    "    return VMat\n",
    "\n",
    "# network in the coupling layer\n",
    "def netW(x, outsize, nbins):\n",
    "    # Note: Need to put in actual matrix, this is just to test\n",
    "    return WMat\n",
    "\n",
    "class PiecewiseQuadratic(tfb.Bijector):\n",
    "    \"\"\"\n",
    "    Piecewise Quadratic: based on 1808.03856\n",
    "    \"\"\"\n",
    "    def __init__(self, D, d, nbins, layer_id=0, validate_args=False, name=\"PiecewiseLinear\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            D: number of dimensions\n",
    "            d: First d units are pass-thru units.\n",
    "        \"\"\"\n",
    "        super(PiecewiseQuadratic, self).__init__(\n",
    "            forward_min_event_ndims=1, validate_args=validate_args, name=name\n",
    "        )\n",
    "        self.D, self.d = D, d\n",
    "        self.id = layer_id\n",
    "        self.nbins = nbins\n",
    "        self.range = np.arange(self.d)\n",
    "        \n",
    "    def W(self, xd):\n",
    "        with tf.variable_scope('W%d' % self.id, reuse=tf.AUTO_REUSE):\n",
    "            return netW(xd, self.D - self.d, self.nbins)\n",
    "              \n",
    "    def V(self, xd):\n",
    "        with tf.variable_scope('V%d' % self.id, reuse=tf.AUTO_REUSE):\n",
    "            return netV(xd, self.D - self.d, self.nbins)\n",
    "        \n",
    "    def _forward(self, x):\n",
    "        \"Calculate forward coupling layer\"\n",
    "        xd, xD = x[:, :self.d], x[:, self.d:]\n",
    "        W = self.W(xd)\n",
    "        V = self.V(xd)\n",
    "        WSum = np.cumsum(W,axis=1)\n",
    "        VSum = np.cumsum((V[:,1:]+V[:,0:-1])*W/2.0,axis=1)\n",
    "        ibins = tf.transpose(tf.searchsorted(WSum,tf.transpose(xD),side='right'))\n",
    "        print(ibins)\n",
    "        alpha = (xD-WSum[self.range,ibins-1])*tf.reciprocal(W[self.range,ibins])\n",
    "        yD = alpha**2/2.0*np.diff(V)[self.range,ibins]*W[self.range,ibins] \\\n",
    "           + alpha*V[self.range,ibins]*W[self.range,ibins] \\\n",
    "           + VSum[self.range,ibins-1]\n",
    "        return tf.concat([xd, yD], axis=1)\n",
    "    \n",
    "    def _inverse(self, y):\n",
    "        \"Calculate inverse coupling layer\"\n",
    "        yd, yD = y[:, :self.d], y[:, self.d:]\n",
    "        W = self.W(yd)\n",
    "        V = self.V(yd)\n",
    "        WSum = np.cumsum(W,axis=1)\n",
    "        VSum = np.cumsum((V[:,1:]+V[:,0:-1])*W/2.0,axis=1)\n",
    "        ibins = tf.transpose(tf.searchsorted(VSum,tf.transpose(yD),side='right'))\n",
    "        print(ibins)\n",
    "        denom = np.diff(V)[self.range,ibins]\n",
    "        beta = (yD - VSum[self.range,ibins-1])/(W[self.range,ibins])\n",
    "        print(yD)\n",
    "        print(VSum[self.range,ibins-1])\n",
    "        print(W[self.range,ibins])\n",
    "        print(beta)\n",
    "        xD = W[self.range,ibins]/denom*(-V[self.range,ibins]+tf.sqrt(V[self.range,ibins]**2+2*beta))+WSum[self.range,ibins-1]\n",
    "        return tf.concat([yd, xD], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = PiecewiseQuadratic(6,3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1 3 3]], shape=(1, 3), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=15489, shape=(1, 6), dtype=float64, numpy=\n",
       "array([[0.1       , 0.2       , 0.3       , 0.01176397, 0.54327221,\n",
       "        0.63007392]])>"
      ]
     },
     "execution_count": 1047,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward=test._forward(np.array([0.1,0.2,0.3,0.01,0.5,0.6]).reshape(1,6))\n",
    "forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1 3 3]], shape=(1, 3), dtype=int32)\n",
      "tf.Tensor([[0.01176397 0.54327221 0.63007392]], shape=(1, 3), dtype=float64)\n",
      "[[0.         0.52529236 0.54008939]]\n",
      "[[0.29250357 0.13220091 0.13870695]]\n",
      "tf.Tensor([[0.04021821 0.13600402 0.64873849]], shape=(1, 3), dtype=float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=15567, shape=(1, 6), dtype=float64, numpy=\n",
       "array([[ 0.1       ,  0.2       ,  0.3       , -0.09173358,  0.441739  ,\n",
       "         0.82523565]])>"
      ]
     },
     "execution_count": 1048,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test._inverse(forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            \n",
    "    def pdf(self,x):\n",
    "        xd, xD = x[:, :self.d], x[:, self.d:]\n",
    "        W = self.W(xd)\n",
    "        V = self.V(xd)\n",
    "        ibins = tf.transpose(tf.searchsorted(np.cumsum(W,axis=1),tf.transpose(xD),side='right')-1)\n",
    "        ibinsp1 = ibins+1\n",
    "        alpha = (xd-np.cumcum(W,axis=1)[np.arange(len(W)),ibins])/W[np.arange(len(W)),ibins]\n",
    "        result = (V[np.arange(len(V)),ibinsp1]-V[np.arange(len(V)),ibins])*alpha+V[np.arange(len(V)),ibins]\n",
    "        return tf.concat([xd, result], axis=1)       \n",
    "\n",
    "    \n",
    "    def _forward_log_det_jacobian(self, x):\n",
    "        \"Calculate log determinant of Coupling Layer\"\n",
    "        xd, xD = x[:, :self.d], x[:, self.d:]\n",
    "        Q = self.Q(xd)\n",
    "        ibins = np.array(np.floor(xD*self.nbins),dtype=np.int32)\n",
    "        return tf.reduce_sum(tf.log(Q[np.arange(len(Q)),ibins]/self.width),axis=-1)\n",
    "    \n",
    "    def _inverse_log_det_jacobian(self, y):\n",
    "        \"Calculate log determinant of Coupling Layer\"\n",
    "        yd, yD = y[:, :self.d], y[:, self.d:]\n",
    "        Q = self.Q(yd)\n",
    "        ibins = np.array(np.floor(yD*self.nbins),dtype=np.int32)\n",
    "        return -tf.reduce_sum(tf.log(Q[np.arange(len(Q)),ibins]/self.width),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03252278,  0.05813606,  0.91280746, -0.46959701,  0.30203176],\n",
       "       [-0.60856429,  0.1897924 ,  0.60831937, -0.77393558,  0.31171796],\n",
       "       [-0.60916156, -0.09294806,  0.65000014, -0.37539562, -0.32373172]])"
      ]
     },
     "execution_count": 797,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diff(VMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95857261, 0.89965627, 1.01485801, 1.02914925, 1.14464312,\n",
       "        0.94965425],\n",
       "       [0.83384493, 1.02240254, 1.2870976 , 0.90594321, 0.7476643 ,\n",
       "        1.24475353],\n",
       "       [0.78848073, 0.9873137 , 1.30597736, 0.5866991 , 1.33639998,\n",
       "        0.88931847]])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=4101, shape=(3,), dtype=float64, numpy=array([0.13723821, 0.21514902, 0.19268482])>"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gather_nd(WMat,[[0,1],[1,3],[2,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3191, shape=(3, 5), dtype=float64, numpy=\n",
       "array([[0.30461836, 0.13723821, 0.19126584, 0.1497618 , 0.21711578],\n",
       "       [0.21034329, 0.17996762, 0.25946607, 0.21514902, 0.135074  ],\n",
       "       [0.23739297, 0.16027006, 0.18968912, 0.21996303, 0.19268482]])>"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
