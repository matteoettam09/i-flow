{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "tfd = tf.contrib.distributions\n",
    "tfb = tfd.bijectors\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTYPE=tf.float32\n",
    "NP_DTYPE=np.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.17694308, 0.12909111, 0.22869545, 0.22170349,\n",
       "        0.24356687],\n",
       "       [0.        , 0.23328833, 0.25628785, 0.13661589, 0.1210035 ,\n",
       "        0.25280443],\n",
       "       [0.        , 0.18656903, 0.13401585, 0.14672721, 0.22498145,\n",
       "        0.30770645]])"
      ]
     },
     "execution_count": 756,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomly assign unnormalized values to piecewise PDF, here we will be using a total of 6 dimensions (|B|=3)\n",
    "QMat = np.random.rand(3,5)\n",
    "# normalize the piecewise PDF such that the integral is 1\n",
    "QMat = tf.nn.softmax(QMat)\n",
    "# Insert a 0 to the beginning to match the size to the bin array\n",
    "QMat = np.insert(QMat,0,0,axis=1)\n",
    "# Print out values of Q for testing purposes\n",
    "QMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network in the coupling layer\n",
    "def net(x, outsize, nbins):\n",
    "    # Note: Need to put in actual matrix, this is just to test\n",
    "    return QMat\n",
    "    return tf.softmax(layers.stack(x, layers.full_connected, [512, 512, out_size]))\n",
    "\n",
    "class PiecewiseLinear(tfb.Bijector):\n",
    "    \"\"\"\n",
    "    Piecewise Linear: based on 1808.03856\n",
    "    \"\"\"\n",
    "    def __init__(self, D, d, nbins, layer_id=0, validate_args=False, name=\"PiecewiseLinear\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            D: number of dimensions\n",
    "            d: First d units are pass-thru units.\n",
    "        \"\"\"\n",
    "        super(PiecewiseLinear, self).__init__(\n",
    "            forward_min_event_ndims=1, validate_args=validate_args, name=name\n",
    "        )\n",
    "        self.D, self.d = D, d\n",
    "        self.id = layer_id\n",
    "        self.nbins = nbins\n",
    "        self.width = 1.0/self.nbins\n",
    "        \n",
    "    def Q(self, xd):\n",
    "        with tf.variable_scope('Q%d' % self.id, reuse=tf.AUTO_REUSE):\n",
    "            return net(xd, self.D - self.d, self.nbins)\n",
    "        \n",
    "    def pdf(self,x):\n",
    "        xd, xD = x[:, :self.d], x[:, self.d:]\n",
    "        Q = self.Q(xd)\n",
    "        ibins = np.array(np.floor(xD*self.nbins),dtype=np.int32)\n",
    "        return tf.concat([xd, Q[np.arange(len(Q)),ibins]], axis=1)\n",
    "        \n",
    "    def _forward(self, x):\n",
    "        \"Calculate forward coupling layer\"\n",
    "        xd, xD = x[:, :self.d], x[:, self.d:]\n",
    "        Q = self.Q(xd)\n",
    "        ibins = np.array(np.floor(xD*self.nbins),dtype=np.int32)\n",
    "        yD = (xD*self.nbins-ibins)*Q[np.arange(len(Q)),ibins+1]+np.cumsum(Q,axis=1)[np.arange(len(Q)),ibins]\n",
    "        return tf.concat([xd, yD], axis=1)\n",
    "        \n",
    "    def _inverse(self, y):\n",
    "        \"Calculate inverse coupling layer\"\n",
    "        yd, yD = y[:, :self.d], y[:, self.d:]\n",
    "        Q = self.Q(yd)\n",
    "        ibins = tf.transpose(tf.searchsorted(np.cumsum(Q,axis=1),tf.transpose(yD),side='right'))-1\n",
    "        xD = ((yD-np.cumsum(Q,axis=1)[np.arange(len(Q)),ibins])*tf.reciprocal(Q[np.arange(len(Q)),ibins+1])+np.array(ibins,dtype=np.float32))*self.width\n",
    "        return tf.concat([yd, xD], axis=1)\n",
    "    \n",
    "    def _forward_log_det_jacobian(self, x):\n",
    "        \"Calculate log determinant of Coupling Layer\"\n",
    "        xd, xD = x[:, :self.d], x[:, self.d:]\n",
    "        Q = self.Q(xd)\n",
    "        ibins = np.array(np.floor(xD*self.nbins),dtype=np.int32)\n",
    "        return tf.reduce_sum(tf.log(Q[np.arange(len(Q)),ibins]/self.width),axis=-1)\n",
    "    \n",
    "    def _inverse_log_det_jacobian(self, y):\n",
    "        \"Calculate log determinant of Coupling Layer\"\n",
    "        yd, yD = y[:, :self.d], y[:, self.d:]\n",
    "        Q = self.Q(yd)\n",
    "        ibins = np.array(np.floor(yD*self.nbins),dtype=np.int32)\n",
    "        return -tf.reduce_sum(tf.log(Q[np.arange(len(Q)),ibins]/self.width),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = PiecewiseLinear(6,3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 2 3]\n",
      " [0 1 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=9290, shape=(2, 6), dtype=float64, numpy=\n",
       "array([[0.1       , 0.2       , 0.3       , 0.30603419, 0.55788413,\n",
       "        0.4673121 ],\n",
       "       [0.6       , 0.5       , 0.4       , 0.        , 0.23328833,\n",
       "        0.09328452]])>"
      ]
     },
     "execution_count": 779,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward = test._forward(np.array([[0.1,0.2,0.3,0.4,0.5,0.6],[0.6,0.5,0.4,0.0,0.2,0.1]]).reshape(2,6))\n",
    "forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2 2 3]\n",
      " [0 1 0]], shape=(2, 3), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=9345, shape=(2, 6), dtype=float64, numpy=\n",
       "array([[0.1, 0.2, 0.3, 0.4, 0.5, 0.6],\n",
       "       [0.6, 0.5, 0.4, 0. , 0.2, 0.1]])>"
      ]
     },
     "execution_count": 780,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test._inverse(forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1 1 0]], shape=(1, 3), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=7603, shape=(1, 6), dtype=float64, numpy=\n",
       "array([[ 1.72240580e-01,  1.72240580e-01,  1.72240580e-01,\n",
       "         2.74970093e-09,  1.68707579e-02, -3.68990786e-03]])>"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse = test._inverse(np.array([0.17224058,0.17224058,0.17224058,0.17224058,0.17224058,0.17224058]).reshape(1,6))\n",
    "inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=7626, shape=(1, 6), dtype=float64, numpy=\n",
       "array([[0.17224058, 0.17224058, 0.17224058, 0.17224058, 0.16482903,\n",
       "        1.18800735]])>"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test._forward(inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=7632, shape=(1, 6), dtype=float64, numpy=\n",
       "array([[0.1       , 0.2       , 0.3       , 0.1375915 , 0.29325187,\n",
       "        0.15774332]])>"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.pdf(np.array([[0.1,0.2,0.3,0.4,0.5,0.6]]).reshape(1,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=6303, shape=(1,), dtype=float64, numpy=array([-0.40662136])>"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test._forward_log_det_jacobian(np.array([[0.1,0.2,0.3,0.4,0.5,0.6]]).reshape(1,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=6310, shape=(1,), dtype=float64, numpy=array([0.40662136])>"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test._inverse_log_det_jacobian(np.array([[0.1,0.2,0.3,0.4,0.5,0.6]]).reshape(1,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3191, shape=(3, 5), dtype=float64, numpy=\n",
       "array([[0.30461836, 0.13723821, 0.19126584, 0.1497618 , 0.21711578],\n",
       "       [0.21034329, 0.17996762, 0.25946607, 0.21514902, 0.135074  ],\n",
       "       [0.23739297, 0.16027006, 0.18968912, 0.21996303, 0.19268482]])>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WMat = np.random.rand(3,5)\n",
    "WMat = tf.nn.softmax(WMat)\n",
    "WMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95857261, 0.89965627, 1.01485801, 1.02914925, 1.14464312,\n",
       "        0.94965425],\n",
       "       [0.83384493, 1.02240254, 1.2870976 , 0.90594321, 0.7476643 ,\n",
       "        1.24475353],\n",
       "       [0.78848073, 0.9873137 , 1.30597736, 0.5866991 , 1.33639998,\n",
       "        0.88931847]])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomly assign unnormalized values to piecewise PDF, here we will be using a total of 6 dimensions (|B|=3)\n",
    "VMat = np.random.rand(3,6)\n",
    "expV = tf.exp(VMat)\n",
    "VDenom = np.sum(0.5*(expV[:,0:5]+expV[:,1:6])*WMat,axis=1,keepdims=True)\n",
    "# normalize the piecewise PDF such that the integral is 1\n",
    "VMat = np.true_divide(expV,VDenom)\n",
    "# Print out values of Q for testing purposes\n",
    "VMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network in the coupling layer\n",
    "def netV(x, outsize, nbins):\n",
    "    # Note: Need to put in actual matrix, this is just to test\n",
    "    return VMat\n",
    "\n",
    "# network in the coupling layer\n",
    "def netW(x, outsize, nbins):\n",
    "    # Note: Need to put in actual matrix, this is just to test\n",
    "    return WMat\n",
    "\n",
    "class PiecewiseQuadratic(tfb.Bijector):\n",
    "    \"\"\"\n",
    "    Piecewise Quadratic: based on 1808.03856\n",
    "    \"\"\"\n",
    "    def __init__(self, D, d, nbins, layer_id=0, validate_args=False, name=\"PiecewiseLinear\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            D: number of dimensions\n",
    "            d: First d units are pass-thru units.\n",
    "        \"\"\"\n",
    "        super(PiecewiseQuadratic, self).__init__(\n",
    "            forward_min_event_ndims=1, validate_args=validate_args, name=name\n",
    "        )\n",
    "        self.D, self.d = D, d\n",
    "        self.id = layer_id\n",
    "        self.nbins = nbins\n",
    "        \n",
    "    def W(self, xd):\n",
    "        with tf.variable_scope('W%d' % self.id, reuse=tf.AUTO_REUSE):\n",
    "            return netW(xd, self.D - self.d, self.nbins)\n",
    "    \n",
    "            \n",
    "    def V(self, xd):\n",
    "        with tf.variable_scope('V%d' % self.id, reuse=tf.AUTO_REUSE):\n",
    "            return netV(xd, self.D - self.d, self.nbins)\n",
    "           \n",
    "    def pdf(self,x):\n",
    "        xd, xD = x[:, :self.d], x[:, self.d:]\n",
    "        W = self.W(xd)\n",
    "        V = self.V(xd)\n",
    "        ibins = tf.transpose(tf.searchsorted(np.cumsum(W,axis=1),tf.transpose(xD),side='right')-1)\n",
    "        ibinsp1 = ibins+1\n",
    "        alpha = (xd-np.cumcum(W,axis=1)[np.arange(len(W)),ibins])/W[np.arange(len(W)),ibins]\n",
    "        result = (V[np.arange(len(V)),ibinsp1]-V[np.arange(len(V)),ibins])*alpha+V[np.arange(len(V)),ibins]\n",
    "        return tf.concat([xd, result], axis=1)\n",
    "        \n",
    "    def _forward(self, x):\n",
    "        \"Calculate forward coupling layer\"\n",
    "        xd, xD = x[:, :self.d], x[:, self.d:]\n",
    "        W = self.W(xd)\n",
    "        V = self.V(xd)\n",
    "        WSum = np.cumsum(W,axis=1)\n",
    "        VSum = np.cumsum(V,axis=1)\n",
    "        ibins = tf.stack([tf.range(self.d),tf.squeeze(tf.searchsorted(WSum,tf.transpose(xD),side='right'))],axis=1)\n",
    "        ibinsp1 = tf.stack([tf.range(self.d),tf.squeeze(tf.searchsorted(WSum,tf.transpose(xD),side='right'))+1],axis=1)\n",
    "        ibinsSum = tf.stack([tf.range(self.d),tf.squeeze(tf.searchsorted(WSum,tf.transpose(xD),side='right'))-1],axis=1)\n",
    "        alpha = (xD-tf.gather_nd(WSum,ibinsSum))/tf.gather_nd(W,ibins)\n",
    "        yD = alpha**2/2.0*tf.gather_nd(np.diff(V),ibins)*tf.gather_nd(W,ibins) \\\n",
    "           + alpha*tf.gather_nd(V,ibins)*tf.gather_nd(W,ibins) \\\n",
    "           + (tf.gather_nd(VSum,ibins)+tf.gather_nd(VSum,ibinsSum))*tf.gather_nd(WSum,ibinsSum)/2.0\n",
    "        return tf.concat([xd, yD], axis=1)\n",
    "        \n",
    "    def _inverse(self, y):\n",
    "        \"Calculate inverse coupling layer\"\n",
    "        yd, yD = y[:, :self.d], y[:, self.d:]\n",
    "        W = self.W(yd)\n",
    "        V = self.V(yd)\n",
    "        WSum = np.cumsum(W,axis=1)\n",
    "        VSum = np.cumsum(V,axis=1)\n",
    "        ibins = tf.transpose(tf.searchsorted(VSum,tf.transpose(yD),side='right'))\n",
    "        ibinsp1 = ibins+1\n",
    "        denom = (V[np.arange(len(V)),ibinsp1]-V[np.arange(len(V)),ibins])\n",
    "        beta = (yD - (VSum[np.arange(len(V)),ibinsp1]+VSum[np.arange(len(V)),ibins])*WSum[np.arange(len(W)),ibins])/(denom*W[np.arange(len(W)),ibins])\n",
    "        xD = W[np.arange(len(W)),ibins]*(-V[np.arange(len(V)),ibins]/denom+tf.sqrt((V[np.arange(len(V)),ibins]/denom)**2+2*beta))+WSum[np.arange(len(W)),ibins]\n",
    "        return tf.concat([yd, xD], axis=1)\n",
    "    \n",
    "    def _forward_log_det_jacobian(self, x):\n",
    "        \"Calculate log determinant of Coupling Layer\"\n",
    "        xd, xD = x[:, :self.d], x[:, self.d:]\n",
    "        Q = self.Q(xd)\n",
    "        ibins = np.array(np.floor(xD*self.nbins),dtype=np.int32)\n",
    "        return tf.reduce_sum(tf.log(Q[np.arange(len(Q)),ibins]/self.width),axis=-1)\n",
    "    \n",
    "    def _inverse_log_det_jacobian(self, y):\n",
    "        \"Calculate log determinant of Coupling Layer\"\n",
    "        yd, yD = y[:, :self.d], y[:, self.d:]\n",
    "        Q = self.Q(yd)\n",
    "        ibins = np.array(np.floor(yD*self.nbins),dtype=np.int32)\n",
    "        return -tf.reduce_sum(tf.log(Q[np.arange(len(Q)),ibins]/self.width),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = PiecewiseQuadratic(6,3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=6040, shape=(1, 6), dtype=float64, numpy=\n",
       "array([[0.1       , 0.2       , 0.3       , 0.51865384, 1.10804107,\n",
       "        1.99007788]])>"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward=test._forward(np.array([0.1,0.2,0.3,0.4,0.5,0.6]).reshape(1,6))\n",
    "forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got array([0, 1, 2])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-462-2482060517d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-457-f1d2d5c4ed77>\u001b[0m in \u001b[0;36m_inverse\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mibinsp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mibins\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mibinsp1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mibins\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0myD\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mVSum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mibinsp1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mVSum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mibins\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mWSum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mibins\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdenom\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mibins\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mxD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mibins\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mibins\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdenom\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mibins\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mWSum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mibins\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxD\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m<<\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0m_check_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0mbegin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m       \u001b[0mend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_check_index\u001b[0;34m(idx)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;31m# TODO(slebedev): IndexError seems more appropriate here, but it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0;31m# will break `_slice_helper` contract.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SLICE_TYPE_ERROR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", got {!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got array([0, 1, 2])"
     ]
    }
   ],
   "source": [
    "test._inverse(forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05891635,  0.11520175,  0.01429124,  0.11549386, -0.19498887],\n",
       "       [ 0.18855761,  0.26469506, -0.38115438, -0.15827892,  0.49708923],\n",
       "       [ 0.19883297,  0.31866366, -0.71927826,  0.74970088, -0.4470815 ]])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diff(VMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95857261, 0.89965627, 1.01485801, 1.02914925, 1.14464312,\n",
       "        0.94965425],\n",
       "       [0.83384493, 1.02240254, 1.2870976 , 0.90594321, 0.7476643 ,\n",
       "        1.24475353],\n",
       "       [0.78848073, 0.9873137 , 1.30597736, 0.5866991 , 1.33639998,\n",
       "        0.88931847]])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=4101, shape=(3,), dtype=float64, numpy=array([0.13723821, 0.21514902, 0.19268482])>"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gather_nd(WMat,[[0,1],[1,3],[2,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3191, shape=(3, 5), dtype=float64, numpy=\n",
       "array([[0.30461836, 0.13723821, 0.19126584, 0.1497618 , 0.21711578],\n",
       "       [0.21034329, 0.17996762, 0.25946607, 0.21514902, 0.135074  ],\n",
       "       [0.23739297, 0.16027006, 0.18968912, 0.21996303, 0.19268482]])>"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
