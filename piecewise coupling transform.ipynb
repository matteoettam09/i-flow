{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "ep=np.exp(-10) #a small number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_max(Qhat): #only takes float type argument\n",
    "    sm=tf.nn.softmax(Qhat)\n",
    "    sess=tf.Session()\n",
    "    Q=sess.run(sm)\n",
    "    sess.close()\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_matrix(labels, K):\n",
    "    \"\"\"\n",
    "    Creates a matrix where the i-th row corresponds to the ith dimension and the jth column\n",
    "                     corresponds to the jth bin. So if dimension i had a label j, then entry (i,j) \n",
    "                     will be 1. \n",
    "                     \n",
    "    Arguments:\n",
    "    labels -- vector containing the bin label from function bin_b\n",
    "    K -- number of bin\n",
    "    \"\"\"\n",
    "    b = labels.flatten()\n",
    "    \n",
    "    # Use tf.one_hot, be careful with the axis\n",
    "    one_hot_matrix = tf.one_hot(b,K,axis=1)\n",
    "    sess = tf.Session()\n",
    "    one_hot = sess.run(one_hot_matrix)\n",
    "    sess.close()\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdf_piecewise_linear(xB,Qn): #inputs: xB, matrix Q =(dim_xB,K) computed from xA, number of bins K\n",
    "    (dim,K)=np.shape(Qn)\n",
    "    b=np.floor(xB*K) #get the bin number of xB (dim,1)\n",
    "    #print(b)\n",
    "    Qindex=np.pad([np.array(range(0,K))],((0,dim-1),(0,0)),\"edge\") #create a matrix outputting Q's index \n",
    "    part=(Qindex<b)*Q #output the part that is inside the sum of Eq(13), (dim,K)\n",
    "    #print(cdfpart)\n",
    "    proj=one_hot_matrix(b,K) #create a mask according to label b, (dim,K)\n",
    "    cdftotal=np.sum(part+Q*proj*(K*xB-b),axis=1,keepdims=True) #output the cdf (dim,1)\n",
    "    return cdftotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inversecdf_pw_linear(c,Qn):\n",
    "    (dim,K)=np.shape(Qn)\n",
    "    b = bin_b(c,Qn)\n",
    "    proj=one_hot_matrix(b,K) #create a mask according to label b, (dim,K)\n",
    "    Qindex=np.pad([np.array(range(0,K))],((0,dim-1),(0,0)),\"edge\") #create a matrix outputting Q's index \n",
    "    \n",
    "    return 1/K*(np.true_divide(c-np.sum((Qindex<b)*Qn, axis=1,keepdims=True),np.sum(proj*Qn,axis=1,keepdims=True))+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_V(V,Wn): #inputs: V =(dim_xB,K+1) and W =(dim_xB,K) computed and normalized from xA\n",
    "    (dim,K)=np.shape(Wn) #get the dimension and number of bins\n",
    "    expV=np.exp(V) #(dim,K+1)\n",
    "    Vdeno=np.sum(0.5*(expV[:,0:K]+expV[:,1:K+1])*Wn,axis=1,keepdims=True) #(dim,1)   \n",
    "    return np.true_divide(expV,Vdeno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_softmax(W):\n",
    "    return soft_max(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_b(xB,Wn):\n",
    "    #print(xB)\n",
    "    #print(Wn)\n",
    "    (dim,K)=np.shape(Wn)\n",
    "    Wcum=np.cumsum(Wn,axis=1) #get the cdf in each dimension of W\n",
    "    mask=((xB-Wcum)>ep) #to avoid the precision issue, compare to a small number epsilon instead of zero\n",
    "    Wtrun=mask*Wcum \n",
    "    b=np.reshape(np.argmax(Wtrun,axis=1),(dim,1))\n",
    "    b=b+np.reshape(np.amax(Wtrun,axis=1)>0,(dim,1))*np.ones((dim,1))\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lerp(xB,Wn,Vn):\n",
    "    (dim,K)=np.shape(Wn)\n",
    "    b=bin_b(xB,Wn)\n",
    "    a=alpha(xB,Wn,b)\n",
    "    #print(b)\n",
    "    #print(a)\n",
    "    proj=one_hot_matrix(b,K) #create a mask according to label b, (dim,K)\n",
    "    #print(proj)\n",
    "    diff= np.sum((-Vn[:,0:K]+Vn[:,1:K+1])*proj,axis=1,keepdims=True) #(dim,1)\n",
    "    #print(diff)\n",
    "    return a*(diff)+np.sum(Vn[:,0:K]*proj,axis=1,keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdf_piecewise_quad(xB,Wn,Vn):\n",
    "    (dim,K)=np.shape(Wn)\n",
    "    b=bin_b(xB,Wn)\n",
    "    #print(b)\n",
    "    a=alpha(xB,Wn,b)\n",
    "    #print(a)\n",
    "    proj=one_hot_matrix(b,K) #create a mask according to label b, (dim,K)\n",
    "    Wb=np.reshape(np.sum(Wn*proj,axis=1),(dim,1))\n",
    "    \n",
    "    Vb=np.sum(Vn[:,0:K]*proj,axis=1,keepdims=True)\n",
    "    Vbplusone=np.sum(Vn[:,1:K+1]*proj,axis=1,keepdims=True)\n",
    "\n",
    "    Windex=np.pad([np.array(range(0,K))],((0,dim-1),(0,0)),\"edge\") #create a matrix outputting W's indices\n",
    "    part=(Windex<b)*(0.5*(Vn[:,0:K]+Vn[:,1:K+1])*Wn)\n",
    "    constant=np.sum(part,axis=1,keepdims=True)\n",
    "    #print(constant)\n",
    "    \n",
    "    return (a*a*0.5*(Vbplusone-Vb)+a*Vb)*Wb+constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inversecdf_pw_quad(c,Wn,Vn):\n",
    "    print(c)\n",
    "    (dim,K)=np.shape(Wn)\n",
    "    VW=0.5*(Vn[:,0:K]+Vn[:,1:K+1])*Wn\n",
    "    print(VW)\n",
    "    b=bin_b(c,VW)\n",
    "    print(b)\n",
    "    proj=one_hot_matrix(b,K) #create a mask according to label b, (dim,K)\n",
    "    Wb=np.reshape(np.sum(Wn*proj,axis=1),(dim,1))\n",
    "    Vb=np.sum(Vn[:,0:K]*proj,axis=1,keepdims=True)\n",
    "    Vbplusone=np.sum(Vn[:,1:K+1]*proj,axis=1,keepdims=True)\n",
    "    \n",
    "    Windex=np.pad([np.array(range(0,K))],((0,dim-1),(0,0)),\"edge\") #create a matrix outputting W's indices   \n",
    "    cprime=c-np.sum((Windex<b)*VW,axis=1,keepdims=True)\n",
    "    r=np.true_divide((Vbplusone-Vb),Wb) # can be less than zero\n",
    "    print(r)\n",
    "    return  np.true_divide(np.sqrt(Vb*Vb+2*cprime*r)-Vb,r)+np.sum((Windex<b)*Wn,axis=1,keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05750805]\n",
      " [0.38194634]\n",
      " [0.69600639]\n",
      " [0.83465197]]\n",
      "[[0.39635567 0.12925801 0.18587676 0.13968668 0.14882288]\n",
      " [0.20474916 0.17056116 0.1852111  0.16439688 0.27508169]\n",
      " [0.24507798 0.12356665 0.24576714 0.17920191 0.20638633]\n",
      " [0.10754031 0.1139931  0.18081527 0.42643702 0.1712143 ]]\n",
      "[[0.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]]\n",
      "[[-0.96672998]\n",
      " [ 0.16332529]\n",
      " [ 1.52514034]\n",
      " [ 1.44485833]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.05750805],\n",
       "       [0.38194634],\n",
       "       [0.69600639],\n",
       "       [0.83465197]])"
      ]
     },
     "execution_count": 916,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "c=np.random.rand(4,1)\n",
    "Wn1=normalize_W(np.random.rand(4,5))\n",
    "Vn1=normalize_V(np.random.rand(4,6),Wn1)\n",
    "xB=inversecdf_pw_quad(c,Wn1,Vn1)\n",
    "cdf_piecewise_quad(xB,Wn1,Vn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
