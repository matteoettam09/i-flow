{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "ep=np.exp(-10) #a small number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_max(Qhat): #only takes float type argument\n",
    "    sm=tf.nn.softmax(Qhat)\n",
    "    sess=tf.Session()\n",
    "    Q=sess.run(sm)\n",
    "    sess.close()\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_matrix(labels, K):\n",
    "    \"\"\"\n",
    "    Creates a matrix where the i-th row corresponds to the ith dimension and the jth column\n",
    "                     corresponds to the jth bin. So if dimension i had a label j, then entry (i,j) \n",
    "                     will be 1. \n",
    "                     \n",
    "    Arguments:\n",
    "    labels -- vector containing the bin label from function bin_b\n",
    "    K -- number of bin\n",
    "    \"\"\"\n",
    "    b = labels.flatten()\n",
    "    \n",
    "    # Use tf.one_hot, be careful with the axis\n",
    "    one_hot_matrix = tf.one_hot(b,K,axis=1)\n",
    "    sess = tf.Session()\n",
    "    one_hot = sess.run(one_hot_matrix)\n",
    "    sess.close()\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdf_piecewise_linear(xB,K,Q): #inputs: xB, matrix Q =(dim_xB,K) computed from xA, number of bins K\n",
    "    print(xB)\n",
    "    Q=soft_max(Q) #pdf\n",
    "    print(Q)\n",
    "    dim=np.shape(xB)[0] #get the dimension of xB\n",
    "    b=np.floor(xB*K) #get the bin number of xB (dim,1)\n",
    "    print(b)\n",
    "    Qindex=np.pad([np.array(range(0,K))],((0,dim-1),(0,0)),\"edge\") #create a matrix outputting Q's index \n",
    "    part=(Qindex<b)*Q #output the part that is inside the sum of Eq(13), (dim,K)\n",
    "    #print(cdfpart)\n",
    "    proj=one_hot_matrix(b,K) #create a mask according to label b, (dim,K)\n",
    "    cdftotal=np.sum(part+Q*proj*(K*xB-b),axis=1,keepdims=True) #output the cdf (dim,1)\n",
    "    return cdftotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test cdf_piecewise_linear(np.ones((3,1)),5,np.random.randint(100,size=(3,5))/70) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_V(V,Wn): #inputs: V =(dim_xB,K+1) and W =(dim_xB,K) computed and normalized from xA\n",
    "    (dim,K)=np.shape(Wn) #get the dimension and number of bins\n",
    "    expV=np.exp(V) #(dim,K+1)\n",
    "    Vdeno=np.sum(0.5*(expV[:,0:K]+expV[:,1:K+1])*Wn,axis=1,keepdims=True) #(dim,1)   \n",
    "    return np.true_divide(expV,Vdeno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_W(W):\n",
    "    return soft_max(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_b_quad(xB,Wn):\n",
    "    #print(xB)\n",
    "    #print(Wn)\n",
    "    (dim,K)=np.shape(Wn)\n",
    "    Wcum=np.cumsum(Wn,axis=1) #get the cdf in each dimension of W\n",
    "    mask=((xB-Wcum)>ep) #to avoid the precision issue, compare to a small number epsilon instead of zero\n",
    "    Wtrun=mask*Wcum \n",
    "    b=np.reshape(np.argmax(Wtrun,axis=1),(dim,1))\n",
    "    b=b+np.reshape(np.amax(Wtrun,axis=1)>0,(dim,1))*np.ones((dim,1))\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lerp(xB,Wn,Vn):\n",
    "    (dim,K)=np.shape(Wn)\n",
    "    b=bin_b_quad(xB,Wn)\n",
    "    a=alpha(xB,Wn,b)\n",
    "    #print(b)\n",
    "    #print(a)\n",
    "    proj=one_hot_matrix(b,K) #create a mask according to label b, (dim,K)\n",
    "    #print(proj)\n",
    "    diff= np.sum((-Vn[:,0:K]+Vn[:,1:K+1])*proj,axis=1,keepdims=True) #(dim,1)\n",
    "    #print(diff)\n",
    "    return a*(diff)+np.sum(Vn[:,0:K]*proj,axis=1,keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdf_piecewise_quad(xB,Wn,Vn):\n",
    "    (dim,K)=np.shape(Wn)\n",
    "    b=bin_b_quad(xB,Wn)\n",
    "    #print(b)\n",
    "    a=alpha(xB,Wn,b)\n",
    "    #print(a)\n",
    "    proj=one_hot_matrix(b,K) #create a mask according to label b, (dim,K)\n",
    "    Wb=np.reshape(np.sum(Wn*proj,axis=1),(dim,1))\n",
    "    \n",
    "    Vb=np.sum(Vn[:,0:K]*proj,axis=1,keepdims=True)\n",
    "    Vbplusone=np.sum(Vn[:,1:K+1]*proj,axis=1,keepdims=True)\n",
    "\n",
    "    Windex=np.pad([np.array(range(0,K))],((0,dim-1),(0,0)),\"edge\") #create a matrix outputting W's indices\n",
    "    part=(Windex<b)*(0.5*(Vn[:,0:K]+Vn[:,1:K+1])*Wn)\n",
    "    constant=np.sum(part,axis=1,keepdims=True)\n",
    "    #print(constant)\n",
    "    \n",
    "    return (a*a*0.5*(Vbplusone-Vb)+a*Vb)*Wb+constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.72339427]\n",
      " [0.53311484]\n",
      " [0.4246731 ]]\n",
      "[[0.16348814 0.18076118 0.16805345 0.24745824 0.24023898]\n",
      " [0.1090726  0.27131492 0.22294379 0.12019002 0.27647868]\n",
      " [0.17452633 0.20760136 0.2192552  0.15584383 0.24277328]]\n",
      "[[0.69464583 0.79815814 1.26264863 0.93450928 1.14257598 0.93951138]\n",
      " [0.83745868 0.75781313 0.65567189 1.54319449 1.21334771 1.03263934]\n",
      " [0.68909242 0.62649155 1.02077434 1.00542867 1.39238143 1.12223574]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.70890496],\n",
       "       [0.42531783],\n",
       "       [0.32915525]])"
      ]
     },
     "execution_count": 819,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xB=np.random.rand(3,1)\n",
    "print(xB)\n",
    "Wn1=normalize_W(np.random.rand(3,5))\n",
    "print(Wn1)\n",
    "Vn1=normalize_V(np.random.rand(3,6),Wn1) #test\n",
    "print(Vn1)\n",
    "cdf_piecewise_quad(xB,Wn1,Vn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
