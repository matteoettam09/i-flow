{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing how to implement Piecewise Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "1. Figure out how to do batching with this code\n",
    "2. Ensure this is the most efficient\n",
    "3. Polish up the mess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use eager execution to make debugging easier (causes tensorflow to evaluate functions immediately)\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Piecewise Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.     , 0.03125, 0.0625 , 0.09375, 0.125  , 0.15625, 0.1875 ,\n",
       "        0.21875, 0.25   , 0.28125, 0.3125 , 0.34375, 0.375  , 0.40625,\n",
       "        0.4375 , 0.46875, 0.5    , 0.53125, 0.5625 , 0.59375, 0.625  ,\n",
       "        0.65625, 0.6875 , 0.71875, 0.75   , 0.78125, 0.8125 , 0.84375,\n",
       "        0.875  , 0.90625, 0.9375 , 0.96875, 1.     ],\n",
       "       [0.     , 0.03125, 0.0625 , 0.09375, 0.125  , 0.15625, 0.1875 ,\n",
       "        0.21875, 0.25   , 0.28125, 0.3125 , 0.34375, 0.375  , 0.40625,\n",
       "        0.4375 , 0.46875, 0.5    , 0.53125, 0.5625 , 0.59375, 0.625  ,\n",
       "        0.65625, 0.6875 , 0.71875, 0.75   , 0.78125, 0.8125 , 0.84375,\n",
       "        0.875  , 0.90625, 0.9375 , 0.96875, 1.     ],\n",
       "       [0.     , 0.03125, 0.0625 , 0.09375, 0.125  , 0.15625, 0.1875 ,\n",
       "        0.21875, 0.25   , 0.28125, 0.3125 , 0.34375, 0.375  , 0.40625,\n",
       "        0.4375 , 0.46875, 0.5    , 0.53125, 0.5625 , 0.59375, 0.625  ,\n",
       "        0.65625, 0.6875 , 0.71875, 0.75   , 0.78125, 0.8125 , 0.84375,\n",
       "        0.875  , 0.90625, 0.9375 , 0.96875, 1.     ]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create bin array with nbins, each with a width of 1.0/nbins. \n",
    "# Note: the bins array contains the bin edges including 0, which makes finding alpha easier later on\n",
    "nbins = 32\n",
    "width = 1.0/nbins\n",
    "bins = np.array([[x*width for x in range(nbins+1)] for i in range(3)])\n",
    "\n",
    "# Print bins for testing purposes\n",
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly assign unnormalized values to piecewise PDF, here we will be using a total of 6 dimensions (|B|=3)\n",
    "Q = np.random.rand(3,nbins)\n",
    "\n",
    "# normalize the piecewise PDF such that the integral is 1\n",
    "total = np.sum(Q,axis=1)\n",
    "Q[0]=Q[0]/total[0]\n",
    "Q[1]=Q[1]/total[1]\n",
    "Q[2]=Q[2]/total[2]\n",
    "\n",
    "# Insert a 0 to the beginning to match the size to the bin array\n",
    "Q = np.insert(Q,0,0,axis=1)\n",
    "\n",
    "# Print out values of Q for testing purposes\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a single phase space point in xB\n",
    "xB = np.random.rand(1,3)\n",
    "\n",
    "# Print out xB for testing purposes\n",
    "xB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# searchsorted finds the location that each xB should be inserted into bins in order to keep the bins array sorted\n",
    "# The transpose is needed to make sure that each point is compared to the right dimension\n",
    "b=tf.searchsorted(bins,tf.transpose(xB),side='right')\n",
    "\n",
    "# The result returns a transpose of a bin location array, take the transpose and print for testing\n",
    "tf.transpose(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01420116, 0.00373426, 0.00795862],\n",
       "       [0.00482652, 0.05512942, 0.02111121],\n",
       "       [0.03036283, 0.05347045, 0.03404066]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test to ensure that the correct Q values are pulled out from the arrays\n",
    "# Note: that each dimension pulls out each bin, there may be a way around this, \n",
    "#       but the desired result is on the diagonal\n",
    "Q[:,b[:,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=123, shape=(), dtype=float64, numpy=2.6650502460893233e-05>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This calculates the PDF for the Piecewise Linear layer, \n",
    "# it takes the result from above and takes the product of the diagonal.\n",
    "# Again there may be a better way to do this\n",
    "tf.reduce_prod(tf.diag_part(Q[:,b[:,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the alpha value in each dimension. \n",
    "# Note: the -1 in the bins term, this is to use the left edge of the bin instead of the right edge\n",
    "alpha = (xB-tf.diag_part(bins[:,b[:,0]-1]))/width\n",
    "\n",
    "# Print out the values of alpha for testing\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=320, shape=(3,), dtype=float64, numpy=array([0.01016649, 0.0007496 , 0.02742373])>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculates the first part of the coupling layer term (\\alpha Q_{ib}) in each dimension\n",
    "tf.diag_part(alpha*Q[:,b[:,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=371, shape=(3,), dtype=float64, numpy=array([0.01420116, 0.38524313, 0.52350583])>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculates the second part of the coupling layer term (sum_{k=1}^{b-1} Q_{ik}) in each dimension\n",
    "# There may be a more efficient way of doing this.\n",
    "tf.diag_part(np.cumsum(Q,axis=1)[:,b[:,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=408, shape=(3,), dtype=float64, numpy=array([0.02436766, 0.38599273, 0.55092956])>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculates the full coupling layer terms\n",
    "tf.diag_part(alpha*Q[:,b[:,0]])+tf.diag_part(np.cumsum(Q,axis=1)[:,b[:,0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
